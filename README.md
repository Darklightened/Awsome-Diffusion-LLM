# Awsome-Diffusion-Language-Models

[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)

A comprehensive list of papers about Diffusion-Language-Models

---

> [!IMPORTANT]
> Contributions welcome:
> - If you have a relevant paper not included in the library, please [contact us](#contact)!  Or, you may also consider submitting 'Pull requests' directly, thank you!
>
> - If you think your paper is more suitable for another category, please [contact us](#contact) or submit 'Pull requests'.
>   
> - If your paper is accepted, you may consider updating the relevant information.
>   
> - Thank you!


---

## ðŸ’¥ News ðŸ’¥
- ðŸ”¥ðŸ”¥ðŸ”¥ Awsome-Diffusion-LM is now open!


---
### Multi-Modal Large Diffusion Language Models

| **Paper Title** | **Year** | **Conference/Journal** | **Remark** |
| --------------- | :----: | :----: | :----: |
| [MMaDA: Multimodal Large Diffusion Language Models](https://openreview.net/pdf?id=dj0TktJcVI](https://arxiv.org/abs/2505.15809))  | 2025 |  Arxiv |
| [LLaDA-V: Large Language Diffusion Models with Visual Instruction Tuning](https://arxiv.org/pdf/2407.07089](https://arxiv.org/abs/2505.16933)) | 2025 |  Arxiv |

### Large Diffusion Language Models

| **Paper Title** | **Year** | **Conference/Journal** | **Remark** |
| --------------- | :----: | :----: | :----: |
| [Large Language Diffusion Models](https://arxiv.org/abs/2502.09992) | 2025 |  Arxiv |
| [LLaDA 1.5: Variance-Reduced Preference Optimization for Large Language Diffusion Models](https://arxiv.org/abs/2505.19223) | 2025 |  Arxiv |
| [Fast-dLLM: Training-free Acceleration of Diffusion LLM by Enabling KV Cache and Parallel Decoding](https://arxiv.org/abs/2505.22618) | 2025 |  Arxiv |
| [Reinforcing the Diffusion Chain of Lateral Thought with Diffusion Language Models](https://arxiv.org/abs/2505.10446) | 2025 |  Arxiv |


## Contact
<!-- **Contact** -->

We welcome all researchers to contribute to this repository.

If you have a related paper that was not added to the library, please contact us.

Email: jake630@snu.ac.kr / wjk9904@snu.ac.kr
